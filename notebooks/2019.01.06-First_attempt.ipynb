{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First thought on interpretation\n",
    "\n",
    "## The task\n",
    "\n",
    "The goal is to identify what features are the most important for the model predictions. I.e. what exact feature changes affect predictions the most. And, if possible, what exact feature _values_ changes affect predictions the most.\n",
    "The interpretation should somehow use Formal Concept Analysis. As example the result of the interpretation should be presented as a Concept Lattice.\n",
    "\n",
    "A model to interpret is supposed to be a Black Box, i.e. one knows nothing about its internal structure. The only known things are:\n",
    "* input data $X$ (the set of features and their values needed for the model to run)\n",
    "* Black Box model as a function $BB: X \\mapsto Y$, where $Y$ is prediction of the model.\n",
    "\n",
    "## Benefits of FCA\n",
    "\n",
    "Formal Concept is a mathematical structure though may be useful for business analysis. Some features in the original dataset may correspond to the same business value. To resolve this one can either change the input data and the model (not our case) or somehow consider it at the stage of interpreting the model. The latter can be done with assigning specific values of different features to the same Formal Concept.\n",
    "\n",
    "## Lack of FCA\n",
    "\n",
    "FCA is good for interpreting the result though it's not always the best model to predict the result. So consider the given Black Box model is the model possible model to solve the task via some metric. Therefore FCA should be used only to interpret the Black Box rather then predicting its output.\n",
    "\n",
    "## Ways to interpret\n",
    "\n",
    "There are 2 basic ways to interpret a model:\n",
    "1. Global - what features are the most important in the model given data $X$. The outcome is the set of features ordered by their contribution to all the rows of data.\n",
    "2. Local - what features are the most important in the model for given row (object) $g\\in X$. The output is the set of features ordered by their contribution into specific rox $x$ of data. If possible - how exactly did they influence the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas of intepretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One feature noise\n",
    "For every feature $f \\in F$ ($F$ is the set of all features), change the values of $f$ to some noise and calculate $$\\Delta Y_f=\\frac{1}{|G|} |\\{g\\in G| |BB(g_f)-BB(g)|>k\\}|  $$, \n",
    "where\n",
    "* $g_f$ - data with nosed feature $f$,\n",
    "* $g$ - the default data,\n",
    "* $k$ - some coefficient corresponding to the precision of the interpretation,\n",
    "* $|*|$ - cardinality of a set\n",
    "\n",
    "Then construct the context "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple feature nose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find every combination of the features that significatly infuence the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SHAP\n",
    "https://github.com/slundberg/shap\n",
    "\n",
    "SHAP is one of the most popular techniques of interpretation. May be we can use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shap features importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shap feature _values_ importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
